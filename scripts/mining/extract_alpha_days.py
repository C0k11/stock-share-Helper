import pandas as pd
import argparse
from pathlib import Path


def categorize_day(row):
    """
    å¢å¼ºç‰ˆåˆ¤å®šé€»è¾‘ï¼šåŠ å…¥é˜²å¾¡æ€§åˆ¤å®šå’Œæ–°é—»æƒé‡
    """
    alpha = row["excess_return"]
    mkt_move = row["market_return_h1"]
    strat_ret = row["strategy_return_h1"]

    # é˜ˆå€¼é…ç½®
    ALPHA_THRESHOLD = 0.003
    BAD_THRESHOLD = -0.003
    CRASH_THRESHOLD = -0.015

    # --- 1. é˜²å¾¡æ€§ Alpha (Defensive Alpha) ---
    if mkt_move < CRASH_THRESHOLD:
        if alpha > 0.01:
            return "DEFENSIVE_ALPHA"
        if strat_ret > 0:
            return "DEFENSIVE_ALPHA_GOLD"

    # --- 2. è¿›æ”»æ€§ Alpha (Active Alpha) ---
    if alpha > ALPHA_THRESHOLD:
        return "ALPHA_DAY"
    if alpha < BAD_THRESHOLD:
        return "BAD_DAY"

    return "NOISE_DAY"


def main():
    parser = argparse.ArgumentParser(description="Extract Rich Alpha Days")
    parser.add_argument(
        "--run-dir",
        type=str,
        required=True,
        help="Path to the specific run directory (e.g., results/phase15_5.../golden_strict)",
    )
    parser.add_argument("--output", type=str, default="alpha_days.csv", help="Output filename")
    args = parser.parse_args()

    run_dir = Path(args.run_dir)
    daily_file = run_dir / "daily.csv"

    if not daily_file.exists():
        print(f"âŒ Error: daily.csv not found in {run_dir}")
        return

    print(f"ğŸ“‚ Loading {daily_file}...")
    df = pd.read_csv(daily_file)

    # ç¡®ä¿æ—¥æœŸæ ¼å¼
    df["date"] = pd.to_datetime(df["date"])

    # --- 1. èšåˆé€»è¾‘ (Aggregation) ---
    # daily.csv æ˜¯ Ticker ç²’åº¦çš„ï¼Œæˆ‘ä»¬éœ€è¦ Date ç²’åº¦çš„
    # å‡è®¾ï¼šuniverse ç­‰æƒé‡é…ç½® (ç®€åŒ–è®¡ç®—ï¼Œä¹Ÿå¯æ ¹æ® positions ç®—åŠ æƒ)

    # é¢„å¤„ç†ï¼šå¡«å……ç¼ºå¤±å€¼ï¼Œé˜²æ­¢èšåˆæŠ¥é”™
    cols_to_fill = ["news_count", "news_score", "volatility_ann_pct", "pnl_h1_net", "fr_h1"]
    for c in cols_to_fill:
        if c not in df.columns:
            df[c] = 0.0

    # --- 1. å¢å¼ºèšåˆé€»è¾‘ (Rich Aggregation) ---
    daily_stats = (
        df.groupby("date")
        .agg(
            {
                "pnl_h1_net": "sum",  # å½“æ—¥ç­–ç•¥ç»„åˆå›æŠ¥ (H1)
                "fr_h1": "median",  # å¸‚åœºå½“æ—¥æ³¢åŠ¨ä¸­ä½æ•° (Market Proxy)
                "volatility_ann_pct": "mean",  # å¹³å‡æ³¢åŠ¨ç‡ç¯å¢ƒ
                "news_count": "sum",  # å½“æ—¥æ–°é—»æ€»é‡
                "news_score": "max",  # å½“æ—¥æœ€å¤§æ–°é—»åˆ†
                "ticker": "count",  # å½“å¤©è¦†ç›–çš„è‚¡ç¥¨æ•°
            }
        )
        .rename(
            columns={
                "pnl_h1_net": "strategy_return_h1",
                "fr_h1": "market_return_h1",
                "volatility_ann_pct": "avg_vol",
                "ticker": "universe_size",
                "news_count": "total_news_vol",
                "news_score": "max_news_impact",
            }
        )
    )

    # --- 2. è®¡ç®—æŒ‡æ ‡ (Metrics) ---
    daily_stats["excess_return"] = daily_stats["strategy_return_h1"] - daily_stats["market_return_h1"]

    # --- 3. æ‰“æ ‡ç­¾ (Labeling) ---
    daily_stats["day_type"] = daily_stats.apply(categorize_day, axis=1)

    # --- 4. å»ºè®®å­—æ®µ (Action Suggestion) ---
    daily_stats["suggest_upsize"] = (daily_stats["day_type"].str.contains("ALPHA")) & (
        daily_stats["total_news_vol"] > 0
    )

    # æ ¼å¼åŒ–è¾“å‡º
    output_df = daily_stats.reset_index().sort_values("date")

    # æ‰“å°ç»Ÿè®¡
    print("\nğŸ“Š Rich Alpha Days Distribution:")
    print(output_df["day_type"].value_counts())

    defensive_days = output_df[output_df["day_type"].str.contains("DEFENSIVE")]
    if not defensive_days.empty:
        print("\nğŸ›¡ï¸ Defensive Wins (Market Crash but we survived):")
        print(defensive_days[["date", "market_return_h1", "strategy_return_h1", "day_type"]])

    # ä¿å­˜
    out_path = run_dir / args.output
    output_df.to_csv(out_path, index=False)
    print(f"\nâœ… Saved Alpha Days to: {out_path}")
    print(f"Sample:\n{output_df[['date', 'strategy_return_h1', 'market_return_h1', 'day_type']].head()}")


if __name__ == "__main__":
    main()
